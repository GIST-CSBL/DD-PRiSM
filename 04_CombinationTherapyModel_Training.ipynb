{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f2c7a-1eff-4032-967d-56de0acd6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 00_CombinationtherapyUtils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d80063",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "base_directory='Base directory that DD-PRiSM located'    \n",
    "batch_size=1024\n",
    "num_workers=0\n",
    "\n",
    "dtype=torch.float\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "predicted_pathway_attention_path=base_directory+'NCI_ALMANAC_combination/Processed/PredictedPathwayAttention_AdamW.csv'\n",
    "predicted_viability_path=base_directory+'NCI_ALMANAC_combination/Processed/PredictedViability_AdamW.csv'\n",
    "\n",
    "if (os.path.isfile(predicted_pathway_attention_path))&(os.path.isfile(predicted_viability_path)):\n",
    "    with open(predicted_pathway_attention_path,\"rb\") as fr:    \n",
    "        nci_almanac_single_attention=pickle.load(fr)       \n",
    "    with open(predicted_viability_path,\"rb\") as fr:    \n",
    "        nci_almanac_single_viability=pickle.load(fr)\n",
    "\n",
    "else:\n",
    "    expression_df=pd.read_csv(base_directory+'NCI_ALMANAC_mono/Processed/Expression_ZNormalized.csv',index_col=0)\n",
    "    valid_gene_list=expression_df.columns\n",
    "    \n",
    "    KEGG_legacy_file='c2.cp.kegg_legacy.v2023.2.Hs.symbols.gmt' #186 gene sets\n",
    "    \n",
    "    GeneSet_List=[]\n",
    "    GeneSetFile=base_directory+'Raw/'+KEGG_legacy_file\n",
    "    with open(GeneSetFile) as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(list(rec) for rec in csv.reader(f, delimiter='\\t')) #reads csv into a list of lists\n",
    "        for row in data:\n",
    "            GeneSet_List.append(row)\n",
    "    \n",
    "    GeneSet_Dic={}\n",
    "    for GeneSet in GeneSet_List:\n",
    "        GeneSet_Dic[GeneSet[0]]=GeneSet[2:]\n",
    "    \n",
    "    GeneSet_Dic_valid={}\n",
    "    for GeneSet in GeneSet_Dic:\n",
    "        GeneSet_tmp=pd.Series(GeneSet_Dic[GeneSet])\n",
    "        GeneSet_tmp=GeneSet_tmp[GeneSet_tmp.isin(valid_gene_list)]\n",
    "        GeneSet_Dic_valid[GeneSet]=GeneSet_tmp\n",
    "    \n",
    "    pathway_list=list(GeneSet_Dic_valid.keys())\n",
    "    \n",
    "    geneexpression_df_dic={}\n",
    "    for pathway in pathway_list:\n",
    "        geneexpression_df_dic[pathway]=pd.read_csv(base_directory+'Input/'+pathway+'.csv',index_col=0)\n",
    "    fingerprint_df=pd.read_csv(base_directory+'Input/Fingerprint_Morgan512.csv',index_col=0)\n",
    "        \n",
    "    geneexpression_tensor_df_path=base_directory+'NCI_ALMANAC_mono/Processed/GeneExpression_Tensor.pickle'\n",
    "        \n",
    "    if (os.path.isfile(geneexpression_tensor_df_path)):        \n",
    "        with open(geneexpression_tensor_df_path,\"rb\") as fr:    \n",
    "            geneexpression_df_by_cellline=pickle.load(fr)\n",
    "    \n",
    "    else:    \n",
    "        pathway_list=list(GeneSet_Dic_valid.keys())\n",
    "        cellline_list=list(geneexpression_df_dic[pathway_list[0]].index)\n",
    "        geneexpression_dic_by_cellline={}\n",
    "        for cellline in tqdm(cellline_list):\n",
    "            list_for_cellline=[]\n",
    "            for pathway in pathway_list:\n",
    "                list_for_cellline.append(geneexpression_df_dic[pathway].loc[cellline].values)\n",
    "            geneexpression_dic_by_cellline[cellline]=list_for_cellline\n",
    "        geneexpression_df_by_cellline=pd.DataFrame.from_dict(geneexpression_dic_by_cellline,orient='index')\n",
    "        geneexpression_df_by_cellline.columns=pathway_list\n",
    "        \n",
    "        with open(geneexpression_tensor_df_path,\"wb\") as fw:    \n",
    "            pickle.dump(geneexpression_df_by_cellline, fw)\n",
    "\n",
    "    nci_almanac_comb=pd.read_csv(base_directory+'NCI_ALMANAC_combination/Processed/NCI_ALMANAC_combination.csv',index_col=0)\n",
    "    nci_almanac_comb1 = nci_almanac_comb[['NSC1','CONCENTRATION1','CELLNAME']]\n",
    "    nci_almanac_comb1.columns = ['NSC','CONCENTRATION','CELLNAME']\n",
    "    nci_almanac_comb2 = nci_almanac_comb[['NSC2','CONCENTRATION2','CELLNAME']]\n",
    "    nci_almanac_comb2.columns = ['NSC','CONCENTRATION','CELLNAME']\n",
    "    nci_almanac_single = pd.concat([nci_almanac_comb1,nci_almanac_comb2],axis=0).drop_duplicates()\n",
    "    nci_almanac_single.CONCENTRATION =[np.around(x,5) for x in nci_almanac_single.CONCENTRATION]\n",
    "    nci_almanac_single['VIABILITY'] = 1 #Dummy viability value for the dataloader\n",
    "    \n",
    "    #Here, we used SequentialSampler, not the RandomSampler, as we need predicted pathway attention and predicted viability for each pairs with their informaiton\n",
    "    nci_almanac_single_dataset = MonotherapyDataset(nci_almanac_single,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "    nci_almanac_single_sampler = BatchSampler(SequentialSampler(nci_almanac_single_dataset),batch_size=batch_size,drop_last=False)\n",
    "    nci_almanac_single_dataloader = DataLoader(nci_almanac_single_dataset,sampler=nci_almanac_single_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "    log_df=pd.read_csv(base_directory+'NCI_ALMANAC_mono/Result/AdamW/Training_Log.csv',index_col=0)\n",
    "    best_epoch=log_df.sort_values(by='Loss').index[0]\n",
    "    pretrained_mono_model_path=base_directory+'NCI_ALMANAC_mono/Result/AdamW/Model/'+str(best_epoch)+'.pt'\n",
    "    pretrained_mono_model=MonotherapyModel(GeneSet_Dic_valid).to(device)\n",
    "    pretrained_mono_model.load_state_dict(torch.load(pretrained_mono_model_path))\n",
    "    pretrained_mono_model.eval()\n",
    "    \n",
    "    target_module='sample_attention_block'\n",
    "    predicted_pathway_attention, predicted_viability = get_intermediate_output(nci_almanac_single_dataloader, pretrained_mono_model, target_module)\n",
    "    \n",
    "    nci_almanac_single_attention=nci_almanac_single.copy().reset_index(drop=True)\n",
    "    nci_almanac_single_attention=nci_almanac_single_attention[['NSC','CELLNAME']]\n",
    "    nci_almanac_single_attention=pd.concat([nci_almanac_single_attention,pd.DataFrame(get_tensor_value(predicted_pathway_attention))],axis=1).drop_duplicates(subset=['NSC','CELLNAME'])\n",
    "    nci_almanac_single_attention.index=pd.MultiIndex.from_frame(nci_almanac_single_attention[['NSC','CELLNAME']])\n",
    "    nci_almanac_single_attention=nci_almanac_single_attention[nci_almanac_single_attention.columns[2:]] #First two columns are NSC and CELLNAME\n",
    "    \n",
    "    nci_almanac_single_viability=nci_almanac_single.copy().reset_index(drop=True)\n",
    "    nci_almanac_single_viability=nci_almanac_single_viability[['NSC','CONCENTRATION','CELLNAME']]\n",
    "    nci_almanac_single_viability=pd.concat([nci_almanac_single_viability,pd.DataFrame(get_tensor_value(predicted_viability))],axis=1).drop_duplicates(subset=['NSC','CONCENTRATION','CELLNAME'])\n",
    "    nci_almanac_single_viability.columns=['NSC','CONCENTRATION','CELLNAME','PREDICTED_VIABILITY']\n",
    "    nci_almanac_single_viability.index=pd.MultiIndex.from_frame(nci_almanac_single_viability[['NSC','CONCENTRATION','CELLNAME']])\n",
    "    nci_almanac_single_viability=nci_almanac_single_viability[['PREDICTED_VIABILITY']]\n",
    "    \n",
    "    with open(predicted_pathway_attention_path,\"wb\") as fw:\n",
    "        pickle.dump(nci_almanac_single_attention, fw)\n",
    "        \n",
    "    with open(predicted_viability_path,\"wb\") as fw:\n",
    "        pickle.dump(nci_almanac_single_viability, fw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee020926-acc2-455e-bc40-322dad070e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_df_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/TrainVal.csv'\n",
    "unseen_pair_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/UnseenPair.csv'\n",
    "unseen_cellline_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/UnseenCellLine.csv'\n",
    "unseen_drug1_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/UnseenDrug1.csv'\n",
    "unseen_drug2_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/UnseenDrug2.csv'\n",
    "unseen_both_path=base_directory+'NCI_ALMANAC_combination/Training/UnseenSetting/UnseenBoth.csv'\n",
    "\n",
    "df_TrainVal=pd.read_csv(trainval_df_path,index_col=0)\n",
    "df_TrainVal=df_TrainVal.sample(frac=1)\n",
    "df_TrainVal=df_TrainVal.reset_index(drop=True)\n",
    "df_TrainVal.CONCENTRATION1=[np.around(x,5) for x in df_TrainVal.CONCENTRATION1]\n",
    "df_TrainVal.CONCENTRATION2=[np.around(x,5) for x in df_TrainVal.CONCENTRATION2]\n",
    "\n",
    "df_UnseenPair=pd.read_csv(unseen_pair_path,index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "df_UnseenPair.CONCENTRATION1=[np.around(x,5) for x in df_UnseenPair.CONCENTRATION1]\n",
    "df_UnseenPair.CONCENTRATION2=[np.around(x,5) for x in df_UnseenPair.CONCENTRATION2]\n",
    "\n",
    "df_UnseenCellline=pd.read_csv(unseen_cellline_path,index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "df_UnseenCellline.CONCENTRATION1=[np.around(x,5) for x in df_UnseenCellline.CONCENTRATION1]\n",
    "df_UnseenCellline.CONCENTRATION2=[np.around(x,5) for x in df_UnseenCellline.CONCENTRATION2]\n",
    "\n",
    "df_UnseenDrug1=pd.read_csv(unseen_drug1_path,index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "df_UnseenDrug1.CONCENTRATION1=[np.around(x,5) for x in df_UnseenDrug1.CONCENTRATION1]\n",
    "df_UnseenDrug1.CONCENTRATION2=[np.around(x,5) for x in df_UnseenDrug1.CONCENTRATION2]\n",
    "\n",
    "df_UnseenDrug2=pd.read_csv(unseen_drug2_path,index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "df_UnseenDrug2.CONCENTRATION1=[np.around(x,5) for x in df_UnseenDrug2.CONCENTRATION1]\n",
    "df_UnseenDrug2.CONCENTRATION2=[np.around(x,5) for x in df_UnseenDrug2.CONCENTRATION2]\n",
    "\n",
    "df_UnseenBoth=pd.read_csv(unseen_both_path,index_col=0).sample(frac=1).reset_index(drop=True)\n",
    "df_UnseenBoth.CONCENTRATION1=[np.around(x,5) for x in df_UnseenBoth.CONCENTRATION1]\n",
    "df_UnseenBoth.CONCENTRATION2=[np.around(x,5) for x in df_UnseenBoth.CONCENTRATION2]\n",
    "\n",
    "trainval_dataset=CombinationDataset(df_TrainVal,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "len_train=int(len(trainval_dataset)*7/8)\n",
    "len_val=len(trainval_dataset)-len_train\n",
    "training_set, validation_set=random_split(trainval_dataset,[len_train,len_val])\n",
    "df_Train=df_TrainVal.iloc[training_set.indices]\n",
    "df_Train_copy=df_Train.copy()\n",
    "df_Train_copy=df_Train_copy[['NSC2','CONCENTRATION2','NSC1','CONCENTRATION1','CELLNAME','VIABILITY']]\n",
    "df_Train=pd.concat([df_Train,df_Train_copy],axis=0)\n",
    "df_Val=df_TrainVal.iloc[validation_set.indices]\n",
    "\n",
    "training_set=CombinationDataset(df_Train,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "training_sampler = BatchSampler(RandomSampler(training_set),batch_size=batch_size,drop_last=False)\n",
    "training_dataloader=DataLoader(training_set,sampler=training_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "validation_set=CombinationDataset(df_Val,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "validation_sampler = BatchSampler(RandomSampler(validation_set),batch_size=batch_size,drop_last=False)\n",
    "validation_dataloader=DataLoader(validation_set,sampler=validation_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "pair_set=CombinationDataset(df_UnseenPair,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "pair_sampler = BatchSampler(SequentialSampler(pair_set),batch_size=batch_size,drop_last=False)\n",
    "pair_dataloader = DataLoader(pair_set,sampler=pair_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "cellline_set=CombinationDataset(df_UnseenCellline,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "cellline_sampler = BatchSampler(SequentialSampler(cellline_set),batch_size=batch_size,drop_last=False)\n",
    "cellline_dataloader = DataLoader(cellline_set,sampler=cellline_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "drug1_set=CombinationDataset(df_UnseenDrug1,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "drug1_sampler = BatchSampler(SequentialSampler(drug1_set),batch_size=batch_size,drop_last=False)\n",
    "drug1_dataloader = DataLoader(drug1_set,sampler=drug1_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "drug2_set=CombinationDataset(df_UnseenDrug2,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "drug2_sampler = BatchSampler(SequentialSampler(drug2_set),batch_size=batch_size,drop_last=False)\n",
    "drug2_dataloader = DataLoader(drug2_set,sampler=drug2_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "both_set=CombinationDataset(df_UnseenBoth,nci_almanac_single_attention,nci_almanac_single_viability)\n",
    "both_sampler = BatchSampler(SequentialSampler(both_set),batch_size=batch_size,drop_last=False)\n",
    "both_dataloader = DataLoader(both_set,sampler=both_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86825c6f-eb64-44fb-92f1-17f02f80c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision=2\n",
    "density_dic=estimate_density(training_set.df.VIABILITY,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2a655-ddca-43bd-80ca-01b8938e51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=1\n",
    "beta=0.5\n",
    "gamma=0.75\n",
    "       \n",
    "num_epochs=1000\n",
    "learning_rate=0.01\n",
    "\n",
    "comb_model=CombinationTherapyModel().to(device)\n",
    "optimizer=AdamW(comb_model.parameters(),lr=learning_rate)\n",
    "loss_fn = CustomLoss(density_dic,alpha, beta, gamma)\n",
    "\n",
    "val_loss_dic={}\n",
    "best_loss=np.inf #Initially, it is inf\n",
    "threshold=0.0005\n",
    "max_patience_lr=10 #Maximum 10 epochs can be trained without improvement\n",
    "max_patience_es=20\n",
    "patience_lr=max_patience_lr #Currently How many epochs can be trained without improvement\n",
    "patience_es=max_patience_es\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_comb(training_dataloader,comb_model,loss_fn,optimizer)\n",
    "    torch.save(comb_model.state_dict(),base_directory+'NCI_ALMANAC_combination/Result/AdamW/Model/'+str(epoch)+'.pt')\n",
    "    val_loss,pcc,rmse=test_comb(validation_dataloader,comb_model,loss_fn)\n",
    "    val_loss_dic[epoch]=[val_loss,pcc,rmse,learning_rate]\n",
    "    print('best_loss: '+str(best_loss))\n",
    "    print('current_val_loss: '+str(val_loss))\n",
    "    \n",
    "    if(val_loss<best_loss-threshold):\n",
    "        best_loss=val_loss\n",
    "        patience_lr=max_patience_lr\n",
    "        patience_es=max_patience_es\n",
    "    else:\n",
    "        patience_lr=patience_lr-1\n",
    "        patience_es=patience_es-1\n",
    "    if patience_lr<=0:\n",
    "        patience_lr=max_patience_lr\n",
    "        learning_rate=learning_rate*0.1\n",
    "        optimizer.param_groups[0]['lr']=learning_rate\n",
    "        print('Learning Rate is changed into '+str(learning_rate))\n",
    "    if patience_es<=0:\n",
    "        print('Early Stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f456c-a785-490d-bfa9-cc1a6acf64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=pd.DataFrame.from_dict(val_loss_dic,orient='index')\n",
    "log_df=pd.DataFrame({'Loss': [get_tensor_value(x) for x in df_tmp[0]],'PCC': df_tmp[1],'RMSE': df_tmp[2],'lr': df_tmp[3].values})\n",
    "log_df.to_csv(base_directory+'NCI_ALMANAC_combination/Result/AdamW/Training_Log.csv')\n",
    "\n",
    "with open(base_directory+'NCI_ALMANAC_combination/Result/AdamW/validation_idx.pickle',\"wb\") as fw:    \n",
    "    pickle.dump(validation_set.df, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b272491",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader=pair_dataloader\n",
    "\n",
    "log_df=pd.read_csv(base_directory+'NCI_ALMANAC_combination/Result/AdamW/Training_Log.csv',index_col=0)\n",
    "best_epoch=log_df.sort_values(by='Loss').index[0]\n",
    "comb_model=CombinationTherapyModel().to(device)\n",
    "comb_model.load_state_dict(torch.load(base_directory+'NCI_ALMANAC_combination/Result/AdamW/Model/'+str(best_epoch)+'.pt'))\n",
    "\n",
    "real,predicted=predict_comb(test_dataloader, comb_model)\n",
    "real=real.cpu().numpy()\n",
    "predicted=predicted.cpu().numpy()\n",
    "\n",
    "print('RMSE: '+str(mean_squared_error(real,predicted)**0.5))\n",
    "print('PCC: '+str(stats.pearsonr(real,predicted)[0]))\n",
    "print('R2: '+str(r2_score(real,predicted)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
