{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cfe5cb-b00a-460d-898a-b85c1b6fcf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 00_Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d293b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler, RandomSampler,random_split\n",
    "from torch.multiprocessing import Pool, Process, set_start_method\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a96592-f6dd-4401-a27d-56b006062111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonotherapyDataset(Dataset):\n",
    "    def __init__(self,dataframe, pathway_list, geneexpression_df_by_cellline, fingerprint_df):\n",
    "        self.df=dataframe\n",
    "        self.pathway_list = pathway_list\n",
    "        self.geneexpression_df_by_cellline=geneexpression_df_by_cellline\n",
    "        self.fingerprint_df=fingerprint_df\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        time0=time.time()\n",
    "        data=[]\n",
    "        df_tmp=self.df.iloc[idx]\n",
    "        cellline_targets=df_tmp['CELLNAME'].values\n",
    "        features_by_cellline=self.geneexpression_df_by_cellline.loc[cellline_targets]\n",
    "        cellline_feature=[torch.Tensor(np.array([x for x in features_by_cellline[pathway].values])).type(torch.float) for pathway in self.pathway_list]\n",
    "        data.append(cellline_feature)\n",
    "        drug_targets=df_tmp['NSC'].values\n",
    "        drug_feature=torch.Tensor(self.fingerprint_df.loc[drug_targets].values).type(torch.float)\n",
    "        data.append(drug_feature)\n",
    "        concentration_feature=torch.Tensor(df_tmp[['CONCENTRATION']].values).type(torch.float)\n",
    "        data.append(concentration_feature)\n",
    "        viability=torch.Tensor(df_tmp[['VIABILITY']].values).type(torch.float)\n",
    "        time1=time.time()\n",
    "        return data,viability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c1ecc5-6552-427a-b99a-32fea886a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonotherapyDataset2device(sample,device):\n",
    "    # sample = [data, viability]\n",
    "    # data = [geneset_data,fingerprint_data,concentration]\n",
    "    # geneset_data = [geneset1, geneset2, ..., geneset186]\n",
    "    device=torch.device(device)\n",
    "    data, viability = sample\n",
    "    for idx, pathway in enumerate(data[0]):\n",
    "        data[0][idx] = pathway.to(device)\n",
    "    data[1] = data[1].to(device)\n",
    "    data[2] = data[2].to(device)\n",
    "    viability = viability.to(device)\n",
    "    return data, viability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea04d00-5b7b-4d39-8923-ef0becea19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dot(tensor1,tensor2,batch_size=1024):\n",
    "    return (tensor1[None]*tensor2).sum(dim=-1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a79a75b4-ae47-4808-9d5f-2eb3c46faa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonotherapyModel(nn.Module):\n",
    "    def __init__(self,GeneSet):\n",
    "        super(MonotherapyModel, self).__init__()\n",
    "\n",
    "        #GeneSet: Dictionary whose key is pathway name and its values are the member gene for each pathway (key)\n",
    "        self.GeneSet=GeneSet\n",
    "        self.pathway_list=list(GeneSet.keys())\n",
    "        self.num_pathway=len(self.pathway_list)\n",
    "        \n",
    "        drug_modules = []\n",
    "        #1st drug layer\n",
    "        drug_modules.append(nn.Linear(512, 256))\n",
    "        drug_modules.append(nn.BatchNorm1d(256))\n",
    "        drug_modules.append(nn.ReLU())\n",
    "        #2nd drug layer\n",
    "        drug_modules.append(nn.Linear(256, 128))\n",
    "        drug_modules.append(nn.BatchNorm1d(128))\n",
    "        drug_modules.append(nn.ReLU())\n",
    "        #create drug block\n",
    "        self.drug_block = nn.Sequential(*drug_modules)\n",
    "\n",
    "        \n",
    "        drug_modules_new = []\n",
    "        #new 1st layer\n",
    "        drug_modules_new.append(nn.Linear(512, 128))\n",
    "        drug_modules_new.append(nn.BatchNorm1d(128))\n",
    "        drug_modules_new.append(nn.ReLU())\n",
    "        #new 2nd drug layer\n",
    "        drug_modules_new.append(nn.Linear(128, 32))\n",
    "        drug_modules_new.append(nn.BatchNorm1d(32))\n",
    "        drug_modules_new.append(nn.ReLU())\n",
    "        #create new drug block\n",
    "        self.new_drug_block = nn.Sequential(*drug_modules_new)\n",
    "        \n",
    "        \n",
    "        #operations like mul, add, subtract, dot are only possible in the forward so safe sub models in lists\n",
    "        #gene set model\n",
    "        self.drug_gene_set_blocks = nn.ModuleDict()\n",
    "        self.gene_attention_blocks = nn.ModuleDict()\n",
    "        self.gene_dot_blocks = nn.ModuleDict()\n",
    "        for pathway in self.pathway_list:\n",
    "            #input_size = number of member genes per pathway\n",
    "            input_size = int(len(self.GeneSet[pathway]))\n",
    "            drug_for_pathway_size = int(input_size/4)+1\n",
    "            \n",
    "            drug_gene_set_modules = []   \n",
    "            #add layers to module\n",
    "            drug_gene_set_modules.append(nn.Linear(32, drug_for_pathway_size))\n",
    "            drug_gene_set_modules.append(nn.BatchNorm1d(drug_for_pathway_size))\n",
    "            drug_gene_set_modules.append(nn.ReLU())\n",
    "            drug_gene_set_block = nn.Sequential(*drug_gene_set_modules)\n",
    "            #store geneset sub block\n",
    "            self.drug_gene_set_blocks[pathway]=drug_gene_set_block\n",
    "            \n",
    "            gene_attention_modules = []\n",
    "            #add layers to module\n",
    "            gene_attention_modules.append(nn.Linear(input_size + drug_for_pathway_size, input_size))\n",
    "            gene_attention_modules.append(nn.BatchNorm1d(input_size))\n",
    "            gene_attention_modules.append(nn.Tanh())\n",
    "            gene_attention_modules.append(nn.Softmax(dim=1))\n",
    "            gene_attention_block = nn.Sequential(*gene_attention_modules)\n",
    "            #store gene attention sub block\n",
    "            self.gene_attention_blocks[pathway]=gene_attention_block\n",
    "            \n",
    "            gene_dot_modules = []\n",
    "            #add layers to module -> dot product will have size of 1\n",
    "            gene_dot_modules.append(nn.BatchNorm1d(1))\n",
    "            gene_dot_modules.append(nn.ReLU())\n",
    "            gene_dot_block = nn.Sequential(*gene_dot_modules)\n",
    "            #safe attention sub block\n",
    "            self.gene_dot_blocks[pathway]=gene_dot_block\n",
    "                \n",
    "        drug_for_pathway_size=int(self.num_pathway/16+1)\n",
    "        #drug dense sample layers\n",
    "        drug_dense_sample_modules = []\n",
    "        drug_dense_sample_modules.append(nn.Linear(32, drug_for_pathway_size))\n",
    "        drug_dense_sample_modules.append(nn.BatchNorm1d(drug_for_pathway_size))\n",
    "        drug_dense_sample_modules.append(nn.ReLU())\n",
    "        #drug dense sample block\n",
    "        self.drug_dense_sample_block = nn.Sequential(*drug_dense_sample_modules)\n",
    "        \n",
    "        #sample attention layers\n",
    "        sample_attention_modules = []\n",
    "        sample_attention_modules.append(nn.Linear(self.num_pathway + drug_for_pathway_size,self.num_pathway))\n",
    "        sample_attention_modules.append(nn.BatchNorm1d(self.num_pathway))\n",
    "        sample_attention_modules.append(nn.Tanh())\n",
    "        sample_attention_modules.append(nn.Softmax(dim=1))\n",
    "        #sample attention block\n",
    "        self.sample_attention_block = nn.Sequential(*sample_attention_modules)\n",
    "        \n",
    "        #sample multiplied layers\n",
    "        sample_multiplied_modules = []\n",
    "        sample_multiplied_modules.append(nn.BatchNorm1d(self.num_pathway))\n",
    "        sample_multiplied_modules.append(nn.ReLU())\n",
    "        self.sample_multiplied_block = nn.Sequential(*sample_multiplied_modules)\n",
    "        \n",
    "        #concatenated model layers\n",
    "        concatenated_modules = []\n",
    "        concatenated_modules.append(nn.Linear(128+self.num_pathway, 128))\n",
    "        concatenated_modules.append(nn.BatchNorm1d(128))\n",
    "        concatenated_modules.append(nn.ReLU())\n",
    "        self.concatenated_block = nn.Sequential(*concatenated_modules)\n",
    "\n",
    "        final_modules = []\n",
    "        #1st final layer\n",
    "        final_modules.append(nn.Linear(128, 32))\n",
    "        final_modules.append(nn.BatchNorm1d(32))\n",
    "        final_modules.append(nn.ReLU())\n",
    "        #2nd final layer\n",
    "        final_modules.append(nn.Linear(32, 8))\n",
    "        final_modules.append(nn.BatchNorm1d(8))\n",
    "        final_modules.append(nn.ReLU())\n",
    "        #3rd final layer\n",
    "        final_modules.append(nn.Linear(8, 2))\n",
    "        final_modules.append(nn.BatchNorm1d(2))\n",
    "        final_modules.append(nn.ReLU())\n",
    "        #create final block\n",
    "        self.final_block = nn.Sequential(*final_modules)\n",
    "        \n",
    "        #curve parameter layer\n",
    "        self.final_y_max = nn.Linear(2, 1)\n",
    "        \n",
    "        self.final_y_min = nn.Linear(2, 1)\n",
    "        self.final_slope = nn.Linear(2, 1)       \n",
    "        self.final_IC50 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, input_feature):\n",
    "        #input_feature = [gene_set_dic, drug_fp, dose]\n",
    "        #-gene_set_dic: dictionary of gene expressions for each pathway \n",
    "        gene_expression_list=input_feature[0]\n",
    "        #-drug_fp: Morgan fingerprint of input drug\n",
    "        drug_fp=input_feature[1]\n",
    "        #-dose: dosage information\n",
    "        dose=input_feature[2]\n",
    "        drug_embed = self.drug_block(drug_fp)\n",
    "        new_drug_embed = self.new_drug_block(drug_fp)\n",
    "        #gene set model\n",
    "        attention_dots = []\n",
    "        \n",
    "        for idx,pathway in enumerate(self.pathway_list):\n",
    "\n",
    "            #gene set calculation\n",
    "            gene_expression=gene_expression_list[idx]\n",
    "            drug_gene_set_model=self.drug_gene_set_blocks[pathway]\n",
    "            gene_attention_model=self.gene_attention_blocks[pathway]\n",
    "            gene_dot_model=self.gene_dot_blocks[pathway]\n",
    "            \n",
    "            drug_gene_set_embed = drug_gene_set_model(new_drug_embed)\n",
    "            #drug feature to gene attention\n",
    "            gene_concat = torch.cat((gene_expression, drug_gene_set_embed), dim=1)\n",
    "            \n",
    "            #gene attention calculation\n",
    "            gene_attention = gene_attention_model(gene_concat)\n",
    "            \n",
    "            attention_dot = batch_dot(gene_expression, gene_attention)\n",
    "            gene_dot = gene_dot_model(attention_dot)\n",
    "\n",
    "            #gene set model\n",
    "            attention_dots.append(gene_dot)\n",
    "\n",
    "        drug_dense_embed = self.drug_dense_sample_block(new_drug_embed)\n",
    "        drug_effected_model_for_attention = attention_dots.copy()  \n",
    "        drug_effected_model_for_attention.append(drug_dense_embed)\n",
    "\n",
    "        gene_set_concat = torch.cat(attention_dots,dim=1)\n",
    "        drug_effected_concat = torch.cat(drug_effected_model_for_attention,dim=1)\n",
    "\n",
    "        sample_attention = self.sample_attention_block(drug_effected_concat)\n",
    "        \n",
    "        sample_multiplied = torch.mul(gene_set_concat, sample_attention)\n",
    "\n",
    "        total_concat = torch.cat([sample_multiplied, drug_embed],dim=1)\n",
    "        \n",
    "        concat_embed = self.concatenated_block(total_concat)\n",
    "        \n",
    "        final_embed = self.final_block(concat_embed)\n",
    "        \n",
    "        final_y_max = self.final_y_max(final_embed)\n",
    "        final_y_min = self.final_y_min(final_embed)\n",
    "        final_slope = self.final_slope(final_embed)\n",
    "        final_ic50 = self.final_IC50(final_embed)\n",
    "          \n",
    "        #final calculations    \n",
    "        final_1 = torch.sub(dose, final_ic50)\n",
    "        final_2 = torch.mul(final_slope, final_1)\n",
    "        final_neg = torch.mul(final_2, -1)\n",
    "        final_sigmoid = torch.sigmoid(final_neg)\n",
    "        final_scale = torch.sub(final_y_max, final_y_min)\n",
    "        final_3 = torch.mul(final_scale, final_sigmoid)\n",
    "        final_4 = torch.add(final_3, final_y_min)\n",
    "        return final_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5910d7-c022-4f10-9d78-31a0eb9d1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mono(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    report_epoch = int(num_batches/10)\n",
    "    time_list=[]\n",
    "    time0=time.time()\n",
    "    print('Training function called at '+str(timestamp2datetime(time0)))\n",
    "    time1=time.time()\n",
    "    time2=time.time()\n",
    "    current_loss = 0\n",
    "    for batch, sample in enumerate(dataloader):\n",
    "        time0=time.time()\n",
    "        if batch%report_epoch==0:\n",
    "            print('==========Current batch is '+str(batch)+'==========')\n",
    "        X,y=MonotherapyDataset2device(sample,device)\n",
    "        pred = model(X)\n",
    "        loss,mse,corr = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        time2=time.time()\n",
    "        current_loss+=loss\n",
    "        time_list.append(time2-time0)\n",
    "        if batch%report_epoch==0:\n",
    "            print('Currently, each batch takes '+str(np.around(np.mean(time_list),1))+' seconds')\n",
    "            print('rmse: '+ str(get_tensor_value(mse)**0.5)+'  pcc: '+str(get_tensor_value(corr))+ '   average loss: '+str(get_tensor_value(current_loss /(batch+1))))\n",
    "    print('Time per batch: '+str(np.mean(time_list[1:]))+' seconds')\n",
    "\n",
    "def test_mono(dataloader, model, loss_fn, num_initial_run=1):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    real_list=[]\n",
    "    predicted_list=[]\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader:\n",
    "            X,y=MonotherapyDataset2device(sample,device)\n",
    "            real_list.append(y)\n",
    "            pred = model(X)\n",
    "            predicted_list.append(pred)\n",
    "            loss,mse,corr=loss_fn(pred,y)\n",
    "            test_loss += loss\n",
    "    test_loss /= num_batches\n",
    "    real_concat=get_tensor_value(torch.cat(real_list).view(-1))\n",
    "    predicted_concat=get_tensor_value(torch.cat(predicted_list).view(-1))\n",
    "    \n",
    "    pcc=stats.pearsonr(predicted_concat,real_concat)[0]\n",
    "    rmse=mean_squared_error(predicted_concat,real_concat)**0.5\n",
    "    r2=r2_score(predicted_concat,real_concat)\n",
    "    \n",
    "    print('========Test result========')\n",
    "    print('----Average Total Loss: '+ str(get_tensor_value(test_loss)))\n",
    "    print('----PCC '+ str(pcc))\n",
    "    print('----RMSE: '+ str(rmse))\n",
    "    print('----R2: '+str(r2))\n",
    "    return test_loss,pcc,rmse\n",
    "\n",
    "def predict_mono(dataloader, model, num_initial_run=1):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    real_list=[]\n",
    "    predicted_list=[]\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader:\n",
    "            X,y=MonotherapyDataset2device(sample,device)\n",
    "            real_list.append(y)\n",
    "            pred = model(X)\n",
    "            predicted_list.append(pred)\n",
    "    real_concat=torch.cat(real_list).view(-1)\n",
    "    predicted_concat=torch.cat(predicted_list).view(-1)\n",
    "\n",
    "    return real_concat, predicted_concat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ijjin_torch_new",
   "language": "python",
   "name": "ijjin_torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
