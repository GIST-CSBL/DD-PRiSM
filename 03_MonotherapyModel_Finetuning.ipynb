{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754f05f-da46-4598-acc8-97829bf6884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 00_MonotherapyUtils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2160dc0-5be7-4cb6-8cb0-b4124835a1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "base_directory='Base directory that DD-PRiSM located'    \n",
    "batch_size=1024\n",
    "num_workers=0\n",
    "\n",
    "expression_df=pd.read_csv(base_directory+'NCI_ALMANAC_mono/Processed/Expression_ZNormalized.csv',index_col=0)\n",
    "valid_gene_list=expression_df.columns\n",
    "\n",
    "KEGG_legacy_file='c2.cp.kegg_legacy.v2023.2.Hs.symbols.gmt' #186 gene sets\n",
    "\n",
    "GeneSet_List=[]\n",
    "GeneSetFile=base_directory+'Raw/'+KEGG_legacy_file\n",
    "with open(GeneSetFile) as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(list(rec) for rec in csv.reader(f, delimiter='\\t')) #reads csv into a list of lists\n",
    "    for row in data:\n",
    "        GeneSet_List.append(row)\n",
    "\n",
    "GeneSet_Dic={}\n",
    "for GeneSet in GeneSet_List:\n",
    "    GeneSet_Dic[GeneSet[0]]=GeneSet[2:]\n",
    "\n",
    "GeneSet_Dic_valid={}\n",
    "for GeneSet in GeneSet_Dic:\n",
    "    GeneSet_tmp=pd.Series(GeneSet_Dic[GeneSet])\n",
    "    GeneSet_tmp=GeneSet_tmp[GeneSet_tmp.isin(valid_gene_list)]\n",
    "    GeneSet_Dic_valid[GeneSet]=GeneSet_tmp\n",
    "\n",
    "pathway_list=list(GeneSet_Dic_valid.keys())\n",
    "\n",
    "geneexpression_df_dic={}\n",
    "for pathway in pathway_list:\n",
    "    geneexpression_df_dic[pathway]=pd.read_csv(base_directory+'Input/'+pathway+'.csv',index_col=0)\n",
    "fingerprint_df=pd.read_csv(base_directory+'Input/Fingerprint_Morgan512.csv',index_col=0)\n",
    "\n",
    "dtype=torch.float\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "geneexpression_tensor_df_path=base_directory+'NCI_ALMANAC_mono/Processed/GeneExpression_Tensor.pickle'\n",
    "\n",
    "trainval_df_path=base_directory+'NCI_ALMANAC_mono/Training/TrainVal.csv'\n",
    "unseenpair_df_path=base_directory+'NCI_ALMANAC_mono/Training/UnseenPair.csv'\n",
    "unseencellline_df_path=base_directory+'NCI_ALMANAC_mono/Training/UnseenCellLine.csv'\n",
    "unseendrug_df_path=base_directory+'NCI_ALMANAC_mono/Training/UnseenDrug.csv'\n",
    "unseenboth_df_path=base_directory+'NCI_ALMANAC_mono/Training/UnseenBoth.csv'\n",
    "\n",
    "if (os.path.isfile(geneexpression_tensor_df_path)):\n",
    "    with open(geneexpression_tensor_df_path,\"rb\") as fr:    \n",
    "        geneexpression_df_by_cellline=pickle.load(fr)\n",
    "\n",
    "else:\n",
    "    pathway_list=list(GeneSet_Dic_valid.keys())\n",
    "    cellline_list=list(geneexpression_df_dic[pathway_list[0]].index)\n",
    "    geneexpression_dic_by_cellline={}\n",
    "    for cellline in tqdm(cellline_list):\n",
    "        list_for_cellline=[]\n",
    "        for pathway in pathway_list:\n",
    "            list_for_cellline.append(geneexpression_df_dic[pathway].loc[cellline].values)\n",
    "        geneexpression_dic_by_cellline[cellline]=list_for_cellline\n",
    "    geneexpression_df_by_cellline=pd.DataFrame.from_dict(geneexpression_dic_by_cellline,orient='index')\n",
    "    geneexpression_df_by_cellline.columns=pathway_list\n",
    "\n",
    "    with open(geneexpression_tensor_df_path,\"wb\") as fw:    \n",
    "        pickle.dump(geneexpression_df_by_cellline, fw)\n",
    "    \n",
    "df_TrainVal=pd.read_csv(trainval_df_path,index_col=0)\n",
    "df_UnseenPair=pd.read_csv(unseenpair_df_path,index_col=0)\n",
    "df_UnseenCellLine=pd.read_csv(unseencellline_df_path,index_col=0)\n",
    "df_UnseenDrug=pd.read_csv(unseendrug_df_path,index_col=0)\n",
    "df_UnseenBoth=pd.read_csv(unseenboth_df_path,index_col=0)\n",
    "\n",
    "df_TrainVal=df_TrainVal.sample(frac=1)\n",
    "df_UnseenPair=df_UnseenPair.sample(frac=1)\n",
    "df_UnseenCellLine=df_UnseenCellLine.sample(frac=1)\n",
    "df_UnseenDrug=df_UnseenDrug.sample(frac=1)\n",
    "df_UnseenBoth=df_UnseenBoth.sample(frac=1)\n",
    "\n",
    "df_TrainVal=df_TrainVal.reset_index(drop=True)\n",
    "df_UnseenPair=df_UnseenPair.reset_index(drop=True)\n",
    "df_UnseenCellLine=df_UnseenCellLine.reset_index(drop=True)\n",
    "df_UnseenDrug=df_UnseenDrug.reset_index(drop=True)\n",
    "df_UnseenBoth=df_UnseenBoth.reset_index(drop=True)\n",
    "\n",
    "trainval_dataset=MonotherapyDataset(df_TrainVal,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "\n",
    "len_train=int(len(trainval_dataset)*8/9)\n",
    "len_val=len(trainval_dataset)-len_train\n",
    "training_set,validation_set=random_split(trainval_dataset,[len_train,len_val])\n",
    "pair_set=MonotherapyDataset(df_UnseenPair,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "cellline_set=MonotherapyDataset(df_UnseenCellLine,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "drug_set=MonotherapyDataset(df_UnseenDrug,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "both_set=MonotherapyDataset(df_UnseenBoth,pathway_list,geneexpression_df_by_cellline,fingerprint_df)\n",
    "\n",
    "training_sampler = BatchSampler(RandomSampler(training_set),batch_size=batch_size,drop_last=False)\n",
    "training_dataloader=DataLoader(training_set,sampler=training_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "validation_sampler = BatchSampler(RandomSampler(validation_set),batch_size=batch_size,drop_last=False)\n",
    "validation_dataloader=DataLoader(validation_set,sampler=validation_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "pair_sampler = BatchSampler(RandomSampler(pair_set),batch_size=batch_size,drop_last=False)\n",
    "pair_dataloader=DataLoader(pair_set,sampler=pair_sampler,batch_size=None,num_workers=num_workers,pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "cellline_sampler = BatchSampler(RandomSampler(cellline_set),batch_size=batch_size,drop_last=False)\n",
    "cellline_dataloader=DataLoader(cellline_set,sampler=cellline_sampler,batch_size=None,num_workers=num_workers, pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "drug_sampler = BatchSampler(RandomSampler(drug_set),batch_size=batch_size,drop_last=False)\n",
    "drug_dataloader=DataLoader(drug_set,sampler=drug_sampler,batch_size=None,num_workers=num_workers, pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "both_sampler = BatchSampler(RandomSampler(both_set),batch_size=batch_size,drop_last=False)\n",
    "both_dataloader=DataLoader(both_set,sampler=both_sampler,batch_size=None,num_workers=num_workers, pin_memory=True)#,multiprocessing_context='spawn')\n",
    "\n",
    "density_path=base_directory+'NCI_ALMANAC_mono/Processed/Density_dic.pickle'\n",
    "try:\n",
    "    with open(density_path,\"rb\") as fr:    \n",
    "        density_dic=pickle.load(fr)\n",
    "\n",
    "except:\n",
    "    precision=2\n",
    "    density_dic=estimate_density(training_set.dataset.df.VIABILITY,precision)\n",
    "    with open(density_path,\"wb\") as fw: \n",
    "        pickle.dump(density_dic, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf8e42-80c4-421c-beb6-f01f91a98b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bn_eval(module):\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf99f6-7b74-4ea6-bc98-5a93d5b66fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alpha=1\n",
    "beta=0.5\n",
    "gamma=0.75\n",
    "learning_rate=1e-2\n",
    "\n",
    "loss_df=pd.read_csv(base_directory+'NCI60/Result/AdamW/Training_Log.csv',index_col=0)\n",
    "best_epoch=loss_df.sort_values(by='Loss').index[0]\n",
    "mono_model=MonotherapyModel(GeneSet_Dic_valid).to(device)\n",
    "mono_model.load_state_dict(torch.load(base_directory+'NCI60/Result/AdamW/Model/'+str(best_epoch)+'.pt'))\n",
    "mono_model.eval()\n",
    "mode='Frozen'\n",
    "if mode=='Frozen':\n",
    "    child_list=[]\n",
    "    for idx,(name, param) in enumerate(mono_model.named_parameters()):\n",
    "        child_list.append(name)\n",
    "    unfrozen_params=child_list[-20:]\n",
    "    for param in mono_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for name, param in mono_model.named_parameters():\n",
    "        if name in unfrozen_params:\n",
    "            param.requires_grad = True\n",
    "mono_model.apply(set_bn_eval)\n",
    "\n",
    "num_epochs=1000\n",
    "learning_rate=0.001\n",
    "\n",
    "optimizer=AdamW(mono_model.parameters(),lr=learning_rate)\n",
    "loss_fn = CustomLoss(density_dic,alpha, beta, gamma)\n",
    "\n",
    "val_loss_dic={}\n",
    "best_loss=np.inf #Initially, it is inf\n",
    "threshold=0.0005\n",
    "max_patience_lr=10 #Maximum 10 epochs can be trained without improvement\n",
    "max_patience_es=20\n",
    "patience_lr=max_patience_lr #Currently How many epochs can be trained without improvement\n",
    "patience_es=max_patience_es\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_mono(training_dataloader,mono_model,loss_fn,optimizer)\n",
    "    torch.save(mono_model.state_dict(),base_directory+'NCI_ALMANAC_mono/Result/AdamW/Model/'+str(epoch)+'.pt')\n",
    "    val_loss,pcc,rmse=test_mono(validation_dataloader,mono_model,loss_fn)\n",
    "    val_loss_dic[epoch]=[val_loss,pcc,rmse,learning_rate]\n",
    "    print('best_loss: '+str(best_loss))\n",
    "    print('current_val_loss: '+str(val_loss))\n",
    "    \n",
    "    if(val_loss<best_loss-threshold):\n",
    "        best_loss=val_loss\n",
    "        patience_lr=max_patience_lr\n",
    "        patience_es=max_patience_es\n",
    "    else:\n",
    "        patience_lr=patience_lr-1\n",
    "        patience_es=patience_es-1\n",
    "    if patience_lr<=0:\n",
    "        patience_lr=max_patience_lr\n",
    "        learning_rate=learning_rate*0.1\n",
    "        optimizer.param_groups[0]['lr']=learning_rate\n",
    "        print('Learning Rate is changed into '+str(learning_rate))\n",
    "    if patience_es<=0:\n",
    "        print('Early Stopping')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27400f19-2784-4beb-b3b3-a47a411f0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp=pd.DataFrame.from_dict(val_loss_dic,orient='index')\n",
    "log_df=pd.DataFrame({'Loss': [get_tensor_value(x) for x in df_tmp[0]],'PCC': df_tmp[1],'RMSE': df_tmp[2],'lr': df_tmp[3].values})\n",
    "log_df.to_csv(base_directory+'NCI_ALMANAC_mono/Result/AdamW/Training_Log.csv')\n",
    "\n",
    "with open(base_directory+'NCI_ALMANAC_mono/Result/AdamW/validation_df.pickle',\"wb\") as fw:    \n",
    "    pickle.dump(validation_set.dataset.df, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
